# Training and Deployment
The files in this folder allow training and deploying a Shap-e type diffusion model. For this, it is necessary to have executed everything necessary in the [dataset](../dataset) folder.

## Prerequisites Installation
Model training consists of fine-tuning Shap-e with custom meshes. This is why Shap-e installation is required. The entire process is based on the [Cap3D](https://github.com/crockwell/Cap3D/tree/main/text-to-3D) repository, so installation and execution is heavily based on the instructions provided there.

### Environment Generation
It is recommended to generate a Python environment within this folder with the command: `python -m venv datasetvenv` and activate it with the command `source datasetenv/bin/activate` to avoid dependency problems.

### Requirements Installation
Once the environment is activated, various prerequisites are installed with the command `pip install -r requirements.txt`

### Shap-e Installation
Shap-e is installed in development mode in case source code alterations need to be made. To do this, while in this folder from a terminal, execute the following commands:

```
git clone https://github.com/openai/shap-e
pip install -e ./shap-e
```

### Possible Errors
If installation errors occur when installing `Shap-e` or the `requirements.txt` file, it is recommended to recreate the environment and install `Shap-e` first before `requirements.txt`.

## Training
For training there is the [finetune_shapE.py](train_eval_scripts/finetune_shapE.py) file, which uses the .pt, .csv and .pickle files generated by following the steps described in the [dataset creation folder](../dataset) to fine-tune the base Shap-e model. To be able to use this file, it must be copied to the [Shap-e root folder](shap-e). Then the following lines need to be modified:

- **Lines 51 and 70**: Change the lines that say `self.captions = pd.read_csv('/home/estudiante/dataset/organs_selected_complete.csv', header=None)` to have the path to the csv file of ids and descriptions of the latent states.
- **Lines 52 and 71**: Change the lines that say `self.valid_uid = list(pickle.load(open('/home/estudiante/dataset/{split}_organs.pickle','rb')))` to have the path to the train and validation id files respectively.
- **Line 248**: Change the epoch saving condition `if epoch in [0, 12, 24]:` so that a model snapshot is saved at the epochs of interest.

Once these changes are made, training can be executed from a terminal as a Python script within the [shap-e](shap-e) folder. For example, the following command was used on the university machine:

```
python finetune_ShapE.py --gpus 1 --batch_size 8 --save_name med_shape_e --latent_code_path /home/estudiante/dataset/dataset_obj/
```

To see more parameters you can use the command `python finetune_ShapE.py -h`. On the other hand, this machine had 24 GB of VRAM, so a batch size of 8 could be used, but when experimenting on machines with 12 GB or less, the usable batch_size is only 1. Note also that `latent_code_path` is added as a parameter with the path where the latent states of the examples are, in .pt format, which were created with the scripts from the [dataset creation folder](../dataset).

When running the script, the model_ckpts model checkpoint folder will be generated within the [Shap-e root folder](shap-e), where the model weights saved in .pth format will be stored. The training statistics csv without header will also be saved at the path `shap-e/logs/med_shap_e.csv`, which for each epoch of interest will have information about:
- Batch duration
- Epoch number
- Batch number within the epoch
- Total batch number
- Train loss
- Validation loss
- Batch loss

### Possible Errors
It may happen that when executing the training script, an error occurs that the `logs` folder and the `model_ckpts` folder do not exist. Therefore, it is recommended to create these folders before executing the script.

## Example generation
To view an example of model generation just move the [small_test.ipynb](example_generation/small_test.ipynb) to the [shap-e](shap-e) folder, and modify the cells 2 and 10 to change the trained model path and prompts respectively, and execute all cells. If you want to change your prompt, just modify cell 10 and run all cells onwards.

If you just want to use an already trained model file, **you still have to install the requirements and Shap-e for it to run**. The same applies for the steps below.

## Quantitative Evaluation
To evaluate the model on test there is the [test_metrics.py](train_eval_scripts/test_metrics.py) file, which has to be copied to the [shap-e](shap-e) folder. After being copied, the following lines are modified:

- **Line 23**: Modified to have the path to the .pt latent files.
- **Line 26**: Modified to have the path to **a single** model weights file. Can be left empty to take the original Shap-e weights.
- **Line 35**: Modified to have the path to the csv file of ids and descriptions of the latent states.
- **Line 36**: Modified to have the path to the test id files.

Once configured, the script can be called with the command `python test_metrics.py` within the [shap-e](shap-e) folder, which will generate a json file with the evaluation MSE error within the `shap-e/test_metrics` folder.

## Qualitative Prediction
For qualitative evaluation there is the [text2ply_shapE.py](train_eval_scripts/text2ply_shapE.py) file, which allows generating meshes in .ply format from the test partition. To do this, the file is copied to the [shap-e](shap-e) folder and the following lines are modified:

- **Line 32**: Modified to have the path to the model snapshot to evaluate.
- **Line 41**: Modified to have the path to the test id files.
- **Line 42**: Modified to have the path to the csv file of ids and descriptions of the latent states.

Once these values are modified, the script is executed with the command `python text2ply_shapE.py` within the [shap-e](shap-e) folder, and all meshes generated for test will be saved in the `shap-e/shapE_inference` folder in .ply format.


## Deployment
For deployment there are the files [main.py](deploy_scripts/main.py) and [run.sh](deploy_scripts/run.sh), which are respectively the main deployment file with streamlit and the bash script to restart execution if there are memory or cache problems. To launch the application, you have to go to the [shap-e](shap-e) folder from the terminal and execute the following commands:

```
sudo chmod +x run.sh
./run.sh 
```

The first is to obtain execution permissions and the second to execute the loop that restarts in case of failures. With this, you can access the URL `http://localhost:8501` in a browser where you can select a model and enter a prompt to generate a mesh in .ply format, which can be downloaded.
